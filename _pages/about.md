---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi, I'm Zongqi He, currently a final year undergraduate student from [Department of Electrical and Electronic Engineering](https://www.polyu.edu.hk/en/eee/), [The Hong Kong Polytechnic University](https://www.polyu.edu.hk/en/). 
I am very fortunate to be advised by [Prof. Kenneth K. M. Lam](https://www.eie.polyu.edu.hk/~enkmlam/). 

My research interest includes computer vision, deep learning , low-level vision and 3D reconstruction.

Here is my [CV](../assets/Curriculum_Vitae.pdf):.


# ğŸ”¥ News
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ Our paper MFGan: OCT Image Super-resolution and Enhancement with Blind Degradation and Multi-frame Fusing is accpeted by [International Workshop on Advanced Image Technology (IWAIT)](https://iwait.online/) 2025.
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ Our paper A Multi-Perceptual Learning Network for Retina OCT Image Denoising and Classification is accpeted by [Asia-Pacific Signal and Information Processing Association](https://www.apsipa.org/) 2024.
- *2022.09*: &nbsp;ğŸ‰ğŸ‰ Our paper for enhancing 3D Gaussian Splatting for novel view synthesis under sparse view is submitted to ICASSP 2025.
- *2022.08*: &nbsp;ğŸ‰ğŸ‰ 2nd place in [AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content](https://codalab.lisn.upsaclay.fr/competitions/17705) in ECCV 2024 and our method Fast Sequential Motion Diffusion (FSMD) is selected to present in the summary [paper](https://arxiv.org/pdf/2409.17256).
- *2022.08*: &nbsp;ğŸ‰ğŸ‰ 3rd place in AIM 2024 Challenge on Sparse Neural Rendering in ECCV 2024 on both [Track 1 - 3 views](https://codalab.lisn.upsaclay.fr/competitions/19222) and [Track 2 - 9 views](https://codalab.lisn.upsaclay.fr/competitions/19223) and our method Enhanced SparseNeRF is selected to present in the summary [paper](https://arxiv.org/pdf/2409.15045).
- *2022.08*: &nbsp;ğŸ‰ğŸ‰ Our paper Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning is accpeted by [AI for Visual Arts Workshop and Challenges (AI4VA)](https://sites.google.com/view/ai4vaeccv2024) in ECCV 2024.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIM@ECCV 2024</div><img src='images/AIM2024.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content](https://arxiv.org/pdf/2409.17256)

Marcos V. Conde, Zhijun Lei, Wen Li, Christos Bampis, Ioannis Katsavounidis, Radu Timofte, **Zongqi He** et al.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIM@ECCV 2024</div><img src='images/AIM2024_ESNeRF.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[AIM 2024 Sparse Neural Rendering Challenge: Methods and Results](https://arxiv.org/abs/2409.15045)

Michal Nazarczuk, Sibi Catley-Chandar, Thomas Tanay, Richard Shaw, Eduardo PÃ©rez-Pellitero, Radu Timofte, **Zongqi He** et al.

</div>
</div>
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AI4VA@ECCV 2024</div><img src='images/MuvieCastONeSDiff_pipe.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning

Yushen Zuo, Jun Xiao, Kin-Chung Chan, Rongkang Dong, Cuixin Yang, **Zongqi He**, Hao Xie, Kin-Man Lam

</div>
</div>

# ğŸ– Honors and Awards
- *2024.08* AIM 2024 Challenge on Sparse Neural Rendering - Track 1 - 3 views - 3rd place.
- *2024.08* AIM 2024 Challenge on Sparse Neural Rendering - Track 2 - 9 views - 3rd place.  
- *2024.08* AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content - 2nd place. 

# ğŸ“– Educations
- *2021.09 - 2024.11 (now)*, The Hong Kong Polytechnic University. 

# ğŸ’» Internships
- *2022.06 - 2022.08*, [Plaper (HK) Limited](https://plaper.hk/), Hong Kong.
